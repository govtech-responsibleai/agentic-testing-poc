{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "records_folder = Path(\"../data/output/hallucination_factchecking/records\")\n",
    "consolidated_folder = Path(\"../data/output/hallucination_factchecking/consolidated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5785"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_files = list(records_folder.glob(\"*.json\"))\n",
    "len(input_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'factcheck_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(in_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     content \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)        \n\u001b[0;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mcontent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfactcheck_result\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m     question \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'factcheck_result'"
     ]
    }
   ],
   "source": [
    "# parse the json files\n",
    "import json\n",
    "all_results = []\n",
    "error_results = []\n",
    "for in_file in input_files:\n",
    "    with open(in_file, \"r\") as f:\n",
    "        content = json.load(f)        \n",
    "        results = content[\"result\"]\n",
    "        id = content[\"id\"]\n",
    "        question = results[\"question\"]\n",
    "        answer = results[\"answer\"]\n",
    "        answerable_by_context = results[\"answerable_by_context\"]\n",
    "        claims_check = results[\"claims_check\"]\n",
    "        for claim_idx, claim in enumerate(claims_check):\n",
    "            claim_text = claim[\"claim\"]\n",
    "            check_type = claim[\"check_type\"]\n",
    "            checkworthy = claim[\"checkworthy\"]\n",
    "            reasoning = claim[\"reasoning\"]\n",
    "            score = claim[\"score\"]\n",
    "            links = claim.get(\"links\", [])\n",
    "            if any([keyword in \" \".join(reasoning).lower() for keyword in [\"unable to retrieve\", \"failed to get\", \"parse\", \"json\", \"rate limit\"]]):\n",
    "                error_results.append({\n",
    "                \"id\": id,\n",
    "                \"claim_idx\": claim_idx,\n",
    "                \"claim_text\": claim_text,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"check_type\": check_type,\n",
    "                \"checkworthy\": checkworthy,\n",
    "                \"reasoning\": reasoning,\n",
    "                \"score\": score,\n",
    "                \"links\": links \n",
    "            })\n",
    "                \n",
    "            else:               \n",
    "                all_results.append({\n",
    "                    \"id\": id,\n",
    "                    \"claim_idx\": claim_idx,\n",
    "                    \"claim_text\": claim_text,\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                    \"check_type\": check_type,\n",
    "                    \"checkworthy\": checkworthy,\n",
    "                    \"reasoning\": reasoning,\n",
    "                    \"score\": score,\n",
    "                    \"links\": links \n",
    "                })\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_results)\n",
    "df_errors = pd.DataFrame(error_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv(\"/home/watsonchua/sls-lea-evaluation/data/input/hd_fc_by_record.csv\")\n",
    "id_to_filename = {}\n",
    "for index, row in df_input.iterrows():\n",
    "    id_to_filename[index] = row[\"filename\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(consolidated_folder / \"hallucination_factchecking_results.csv\", index=False)\n",
    "\n",
    "def add_topic_profile_to_df(df_in):\n",
    "    df_in[\"filename\"] = df_in[\"id\"].map(id_to_filename)\n",
    "    df_in[\"topic\"] = df_in[\"filename\"].apply(lambda x: x.split(\"_\", maxsplit=1)[0])\n",
    "    df_in[\"profile\"] = df_in[\"filename\"].apply(lambda x: x.split(\"_\", maxsplit=1)[1][:-5])\n",
    "    df_in.sort_values(by=[\"id\", \"claim_idx\"], inplace=True)\n",
    "    return df_in\n",
    "\n",
    "df_processed = add_topic_profile_to_df(df)\n",
    "df_errors_processed = add_topic_profile_to_df(df_errors)\n",
    "\n",
    "\n",
    "df_processed.to_csv(consolidated_folder / \"hallucination_factchecking_results.csv\", index=False)\n",
    "df_errors_processed.to_csv(consolidated_folder / \"hallucination_factchecking_errors.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1346 2820 4479\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(df_processed[df_processed[\"check_type\"] == \"hallucination\"][\"id\"].unique()),\n",
    "    len(df_processed[df_processed[\"check_type\"] == \"factuality\"][\"id\"].unique()),\n",
    "    len(df_processed[df_processed[\"check_type\"] == \"NA\"][\"id\"].unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IDs where all check_types are NA: 1618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "profile\n",
       "bad_english     2147\n",
       "good            1103\n",
       "out_of_topic    2267\n",
       "unfactual       1865\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all unique IDs\n",
    "all_ids = df_processed[\"id\"].unique()\n",
    "\n",
    "# For each ID, check if all its entries have check_type as NA\n",
    "ids_with_all_na = []\n",
    "for id_val in all_ids:\n",
    "    id_entries = df_processed[df_processed[\"id\"] == id_val]\n",
    "    if (id_entries[\"check_type\"] == \"NA\").all():\n",
    "        ids_with_all_na.append(id_val)\n",
    "\n",
    "print(f\"Number of IDs where all check_types are NA: {len(ids_with_all_na)}\")\n",
    "df_processed[df_processed[\"id\"].isin(ids_with_all_na)].groupby(\"profile\").size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profile       check_type     score         \n",
       "bad_english   NA             NA                3509\n",
       "              factuality     PASS              1503\n",
       "                             FAIL                19\n",
       "              hallucination  PASS              1397\n",
       "                             FAIL               266\n",
       "good          NA             NA                2427\n",
       "              factuality     PASS              1838\n",
       "                             FAIL                37\n",
       "                             PARTIALLY_PASS       1\n",
       "              hallucination  PASS              1666\n",
       "                             FAIL               275\n",
       "out_of_topic  NA             NA                4805\n",
       "              factuality     PASS              2728\n",
       "                             FAIL                11\n",
       "              hallucination  PASS               384\n",
       "                             FAIL                57\n",
       "unfactual     NA             NA                3989\n",
       "              factuality     PASS              2131\n",
       "                             FAIL                24\n",
       "                             UNVERIFIED           2\n",
       "              hallucination  PASS              1708\n",
       "                             FAIL               201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.groupby([\"profile\", \"check_type\"]).value_counts([\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5784"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_processed[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_type\n",
       "NA               14730\n",
       "factuality        8294\n",
       "hallucination     5954\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break down by claims\n",
    "df_processed.groupby(\"check_type\")[\"id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_type\n",
       "NA               3400\n",
       "factuality       1376\n",
       "hallucination    1008\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break down by questions\n",
    "df_processed.drop_duplicates(\"id\").groupby(\"check_type\")[\"id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "PASS              8200\n",
       "FAIL                91\n",
       "UNVERIFIED           2\n",
       "PARTIALLY_PASS       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[df_processed[\"check_type\"]==\"factuality\"][\"score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "PASS    5155\n",
       "FAIL     799\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[df_processed[\"check_type\"]==\"hallucination\"][\"score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "NA                14730\n",
       "PASS              13355\n",
       "FAIL                890\n",
       "UNVERIFIED            2\n",
       "PARTIALLY_PASS        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[\"score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375219375219376"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_rate = df_processed[df_processed[\"score\"] == \"PASS\"].shape[0] / (df_processed[df_processed[\"score\"] == \"PASS\"].shape[0] + df_processed[df_processed[\"score\"] == \"FAIL\"].shape[0])\n",
    "pass_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8658045011756802\n",
      "0.9890242431552285\n"
     ]
    }
   ],
   "source": [
    "hallucination_pass_rate = df_processed[df_processed[\"check_type\"] == \"hallucination\"][\"score\"].value_counts()[\"PASS\"] / (df_processed[df_processed[\"check_type\"] == \"hallucination\"][\"score\"].value_counts()[\"PASS\"] + df_processed[df_processed[\"check_type\"] == \"hallucination\"][\"score\"].value_counts()[\"FAIL\"])\n",
    "print(hallucination_pass_rate)\n",
    "\n",
    "factuality_pass_rate = df_processed[df_processed[\"check_type\"] == \"factuality\"][\"score\"].value_counts()[\"PASS\"] / (df_processed[df_processed[\"check_type\"] == \"factuality\"][\"score\"].value_counts()[\"PASS\"] + df_processed[df_processed[\"check_type\"] == \"factuality\"][\"score\"].value_counts()[\"FAIL\"])\n",
    "print(factuality_pass_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4916833459866105\n"
     ]
    }
   ],
   "source": [
    "checkworthy_pass_rate = df_processed[df_processed[\"checkworthy\"] == \"PASS\"].shape[0] / (df_processed[df_processed[\"checkworthy\"] == \"PASS\"].shape[0] + df_processed[df_processed[\"checkworthy\"] == \"FAIL\"].shape[0])\n",
    "print(checkworthy_pass_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2913639/1346527862.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  hallucination_fail_df = df_processed[df_processed[\"check_type\"] == \"hallucination\"][df_processed[\"score\"] == \"FAIL\"]\n"
     ]
    }
   ],
   "source": [
    "# Hallucination failure examples\n",
    "hallucination_fail_df = df_processed[df_processed[\"check_type\"] == \"hallucination\"][df_processed[\"score\"] == \"FAIL\"]\n",
    "hallucination_fail_df.drop(columns=[\"links\"]).to_csv(consolidated_folder / \"hallucination_fail_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2913639/4133744728.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  factuality_fail_df = df_processed[df_processed[\"check_type\"] == \"factuality\"][df_processed[\"score\"] == \"FAIL\"]\n"
     ]
    }
   ],
   "source": [
    "# Factuality failure examples\n",
    "factuality_fail_df = df_processed[df_processed[\"check_type\"] == \"factuality\"][df_processed[\"score\"] == \"FAIL\"]\n",
    "factuality_fail_df.drop(columns=[\"links\"]).to_csv(consolidated_folder / \"factuality_fail_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factcheck hallucination failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "hallucination_fail_fact_check_records_folder = Path(\"/home/watsonchua/sls-lea-evaluation/data/output/hallucination_factchecking/hallucination_fail_fact_check_records\")\n",
    "hallucination_fail_fact_check_records_files = list(hallucination_fail_fact_check_records_folder.glob(\"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hallucination_fail_fact_check_records_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "all_hc_fc_results = []\n",
    "all_hc_fc_errors = []\n",
    "for file in hallucination_fail_fact_check_records_files:\n",
    "    with open(file, \"r\") as f:\n",
    "        try:\n",
    "            content = json.load(f) \n",
    "        except json.JSONDecodeError as je:\n",
    "            print(str(je))\n",
    "            continue\n",
    "        claim_id = content\n",
    "        results = content[\"factcheck_result\"]\n",
    "        id = content[\"question_id\"]\n",
    "        # question = content[\"question\"]\n",
    "        # answer = content[\"answer\"]\n",
    "        # answerable_by_context = results[\"answerable_by_context\"]\n",
    "        claims_check = results[\"claims_check\"]\n",
    "        claim_idx = content[\"claim_id\"]            \n",
    "        claim_text = content[\"claim\"]\n",
    "        # claim_text = claim[\"claim\"]\n",
    "        claim = claims_check[0]\n",
    "        # claim_idx = claim[\"claim_id\"]\n",
    "        check_type = claim[\"check_type\"]\n",
    "        # checkworthy = claim[\"checkworthy\"]\n",
    "        reasoning = claim[\"reasoning\"]\n",
    "        score = claim[\"score\"]\n",
    "        links = claim.get(\"links\", [])\n",
    "        if any([keyword in \" \".join(reasoning).lower() for keyword in [\"unable to retrieve\", \"failed to get\", \"parse\", \"json\", \"rate limit\"]]):\n",
    "            all_hc_fc_errors.append({\n",
    "            \"id\": id,\n",
    "            \"claim_idx\": claim_idx,\n",
    "            \"claim_text\": claim_text,\n",
    "            # \"question\": question,\n",
    "            # \"answer\": answer,\n",
    "            \"check_type\": check_type,\n",
    "            # \"checkworthy\": None,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"score\": score,\n",
    "            \"links\": links \n",
    "        })\n",
    "            \n",
    "        else:               \n",
    "            all_hc_fc_results.append({\n",
    "                \"id\": id,\n",
    "                \"claim_idx\": claim_idx,\n",
    "                \"claim_text\": claim_text,\n",
    "                # \"question\": question,\n",
    "                # \"answer\": answer,\n",
    "                \"check_type\": check_type,\n",
    "                # \"checkworthy\": None,\n",
    "                \"reasoning\": reasoning,\n",
    "                \"score\": score,\n",
    "                \"links\": links \n",
    "            })\n",
    "\n",
    "\n",
    "df_hallucination_failure_checks = pd.DataFrame(all_hc_fc_results)\n",
    "df_hallucination_failure_checks_processed = add_topic_profile_to_df(df_hallucination_failure_checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "PASS    734\n",
       "FAIL     14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hallucination_failure_checks_processed[\"score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profile       score\n",
       "bad_english   PASS     250\n",
       "              FAIL       2\n",
       "good          PASS     256\n",
       "              FAIL       3\n",
       "out_of_topic  PASS      54\n",
       "              FAIL       1\n",
       "unfactual     PASS     174\n",
       "              FAIL       8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hallucination_failure_checks_processed.groupby([\"profile\"]).value_counts([\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15: ['Rubber bands are used in various ways in robotics, particularly in the VEX IQ Robotics platform.',\n",
       "  'Rubber bands can assist with gripping mechanisms, motor efficiency, and energy storage in robots.',\n",
       "  'Rubber bands can be used to drive movement and support mechanical tasks by stretching and storing potential energy.'],\n",
       " 77: ['Cows need to be pregnant and give birth to initiate milk production. This process is triggered by hormonal changes associated with pregnancy and calving.',\n",
       "  'Once a cow has given birth, she can continue to produce milk for an extended period through regular milking and proper nutrition, even if she is not pregnant again.',\n",
       "  'The regular removal of milk from the udder is essential for sustaining continued production. If a cow is not milked, milk production will eventually stop.'],\n",
       " 200: ['The search results and fetched content did not provide specific information directly linking successful metrics to the expansion of Marine Protected Areas (MPAs) or the implementation of new management practices.',\n",
       "  'The articles retrieved focused more on the impact of the COVID-19 pandemic on marine science and the challenges faced by researchers, rather than on the direct relationship between successful metrics and MPA expansion or new management practices.'],\n",
       " 482: ['The content from the Institute for Energy Research suggests that wind energy, despite receiving substantial subsidies, is still considered expensive and unreliable compared to traditional energy sources like coal, natural gas, and nuclear power.',\n",
       "  'The article mentions that wind and solar energy are heavily dependent on government subsidies and mandates, without which they could not compete with more reliable and affordable energy sources.',\n",
       "  'It also highlights that the higher the subsidies for wind and solar energy, the more outlays from the government and consumers will become necessary to reach climate goals, indicating that wind energy has not significantly reduced energy costs over time.'],\n",
       " 88: ['Oxygen is essential for most macroscopic and complex life forms, including humans, animals, and plants, which rely on aerobic respiration to produce energy.',\n",
       "  'However, there are exceptions to this rule. Certain anaerobic organisms, such as some bacteria and archaea, do not require oxygen and can thrive in oxygen-deprived environments.',\n",
       "  'The discovery of Henneguya salminicola, a multicellular animal that does not require oxygen, further demonstrates that not all living beings need oxygen to survive.'],\n",
       " 598: ['Social media platforms like X (formerly Twitter), TikTok, Facebook, and Instagram are significant in political discourse, with many users engaging with political content on these platforms.',\n",
       "  'Social media has transformed political campaigns, allowing candidates to communicate directly with voters, raise funds, and conduct interviews, as seen in the 2024 U.S. presidential election.',\n",
       "  'The influence of social media on politics includes both positive aspects, such as democratizing information and enabling direct communication, and negative aspects, such as the spread of misinformation and increased polarization.',\n",
       "  'There are ongoing discussions and efforts to address the challenges posed by social media in politics, including misinformation and the need for responsible use and engagement.'],\n",
       " 377: ['The health of marine ecosystems is mixed, with some areas showing improvement while others continue to face significant challenges.',\n",
       "  'A report on 234 marine protected areas indicated that more than 60% showed improvement in nature conservation and human wellbeing.',\n",
       "  'However, widespread marine heatwaves in 2023-2024 have negatively impacted ocean processes, marine species, ecosystems, and coastal communities.',\n",
       "  'In specific regions like the Gulf of Mannar, there has been a slight recovery in coral cover, but overall coral health remains below historical baselines.'],\n",
       " 193: ['The search results provided information primarily about the invention of the wheel around 3500 BCE, but did not provide sufficient information about bark canoes, sledges, or carts pulled by livestock from the same period.',\n",
       "  \"The content fetched from the provided link focused on the wheel's development and its impact on transportation and industry, but did not mention bark canoes or sledges.\"],\n",
       " 262: ['The search results and fetched content do not provide specific information about the role of pet shops and ice cream parlours in the urban ecosystem shaped by transportation.',\n",
       "  'The available content discusses urban ecosystem services, the role of urban animals, and the importance of maintaining ecosystem services in urban landscapes, but does not mention pet shops or ice cream parlours.'],\n",
       " 303: ['Cats can instinctively swim and some breeds even enjoy it.',\n",
       "  'Certain cat breeds like the Turkish Van, Maine Coon, and Bengal are known for their affinity for water.',\n",
       "  'Cats have webbed feet which help them swim, but their swimming ability is generally not as specialized as that of fish.',\n",
       "  'Fish are naturally adapted to live and swim in water, with bodies designed for efficient movement in aquatic environments.'],\n",
       " 554: ['Galileo did not actually drop objects from the Leaning Tower of Pisa. Instead, he described a hypothetical experiment involving the simultaneous release of two objects of different masses from the same height.',\n",
       "  'The popular depiction of Galileo dropping weights from the Leaning Tower of Pisa is more myth than historical reality.'],\n",
       " 481: ['Alpine meadows and forests are typically found at higher elevations where the conditions are suitable for their specific flora and fauna.',\n",
       "  'Alpine meadows are characterized by short growing seasons, cold temperatures, and harsh weather conditions, which are not typical of lower elevations.',\n",
       "  'Forests at lower elevations are usually dominated by deciduous or coniferous trees, not the specialized vegetation found in alpine meadows.'],\n",
       " 313: ['The search results did not provide specific information about the adaptations of Tembusu and Rain Tree for efficient photosynthesis in Singapore.',\n",
       "  'The general information about tropical rainforest plant adaptations includes mechanisms to prevent waterlogging, maximize sunlight exposure, and grow in nutrient-poor soils, but does not specifically mention Tembusu or Rain Tree.'],\n",
       " 405: ['The search results indicate that bees do produce beeswax, with detailed explanations on how beeswax is made by bees.',\n",
       "  'However, there is no information in the search results about bees producing honey.']}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hallucination_failure_checks_processed[df_hallucination_failure_checks_processed[\"score\"] == \"FAIL\"][\"reasoning\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factcheck factcheck failures due to json parsing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "factuality_fail_factcheck_records_folder = Path(\"/home/watsonchua/sls-lea-evaluation/data/output/hallucination_factchecking/factcheck_json_fail_fact_check_records\")\n",
    "factuality_fail_factcheck_records_files = list(factuality_fail_factcheck_records_folder.glob(\"*.json\"))\n",
    "len(factuality_fail_factcheck_records_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_records = []\n",
    "for file in factuality_fail_factcheck_records_files:\n",
    "    try:\n",
    "        data = json.load(open(file))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(e)\n",
    "        print(file)\n",
    "        continue\n",
    "    all_records.append(data)\n",
    "\n",
    "df_factuality_failure_checks = pd.DataFrame(all_records) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "4\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "factuality_fail_factcheck_passes = 0\n",
    "factuality_fail_factcheck_fails = 0\n",
    "for index, row in df_factuality_failure_checks.iterrows():\n",
    "    factcheck_result = row[\"factcheck_result\"][\"claims_check\"][0][\"score\"]\n",
    "    if factcheck_result == \"PASS\":\n",
    "        factuality_fail_factcheck_passes += 1\n",
    "    elif factcheck_result == \"FAIL\":\n",
    "        factuality_fail_factcheck_fails += 1\n",
    "\n",
    "print(factuality_fail_factcheck_passes)\n",
    "print(factuality_fail_factcheck_fails)\n",
    "print(factuality_fail_factcheck_passes / (factuality_fail_factcheck_passes + factuality_fail_factcheck_fails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(consolidated_folder / \"hallucination_factchecking_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                          3451\n",
       "claim_idx                                                      0\n",
       "claim_text         Biking may seem similar to riding a tricycle.\n",
       "question       I don't think biking is that great! I mean, is...\n",
       "answer         I appreciate your perspective! While biking ma...\n",
       "check_type                                                   NaN\n",
       "checkworthy                                                 FAIL\n",
       "reasoning                           ['Claim is not checkworthy']\n",
       "score                                                        NaN\n",
       "links                                                         []\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(consolidated_folder / \"hallucination_factchecking_results_with_filename.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>claim_idx</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>check_type</th>\n",
       "      <th>checkworthy</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>score</th>\n",
       "      <th>links</th>\n",
       "      <th>filename</th>\n",
       "      <th>topic</th>\n",
       "      <th>profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Food security in Singapore is defined as hav...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Food_security'...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore relies heavily on food imports, maki...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Singapore imports over 90% of its food due t...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://amycookseats.com/how-much-food-does-...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ensuring food security helps maintain public h...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Food security ensures that individuals have ...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://www.maidencap.com/insights/the-impor...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The government actively works on strategies to...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>[\"The Singapore government has implemented the...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://www.mse.gov.sg/policies/food', 'http...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15403</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Singapore ensures a stable food supply through...</td>\n",
       "      <td>Oh, cool! So since Singapore relies on imports...</td>\n",
       "      <td>Singapore ensures a stable food supply through...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Singapore employs several key strategies to ...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://singaporeainews.org/blogs/news/singa...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  claim_idx                                         claim_text  \\\n",
       "8495    0          0  Food security in Singapore means ensuring that...   \n",
       "8496    0          1  Singapore relies heavily on food imports, maki...   \n",
       "8497    0          2  Ensuring food security helps maintain public h...   \n",
       "8498    0          3  The government actively works on strategies to...   \n",
       "15403   1          0  Singapore ensures a stable food supply through...   \n",
       "\n",
       "                                                question  \\\n",
       "8495   I want you to help me understand what food sec...   \n",
       "8496   I want you to help me understand what food sec...   \n",
       "8497   I want you to help me understand what food sec...   \n",
       "8498   I want you to help me understand what food sec...   \n",
       "15403  Oh, cool! So since Singapore relies on imports...   \n",
       "\n",
       "                                                  answer  check_type  \\\n",
       "8495   Food security in Singapore means ensuring that...  factuality   \n",
       "8496   Food security in Singapore means ensuring that...  factuality   \n",
       "8497   Food security in Singapore means ensuring that...  factuality   \n",
       "8498   Food security in Singapore means ensuring that...  factuality   \n",
       "15403  Singapore ensures a stable food supply through...  factuality   \n",
       "\n",
       "      checkworthy                                          reasoning score  \\\n",
       "8495         PASS  ['Food security in Singapore is defined as hav...  PASS   \n",
       "8496         PASS  ['Singapore imports over 90% of its food due t...  PASS   \n",
       "8497         PASS  ['Food security ensures that individuals have ...  PASS   \n",
       "8498         PASS  [\"The Singapore government has implemented the...  PASS   \n",
       "15403        PASS  ['Singapore employs several key strategies to ...  PASS   \n",
       "\n",
       "                                                   links  \\\n",
       "8495   ['https://en.wikipedia.org/wiki/Food_security'...   \n",
       "8496   ['https://amycookseats.com/how-much-food-does-...   \n",
       "8497   ['https://www.maidencap.com/insights/the-impor...   \n",
       "8498   ['https://www.mse.gov.sg/policies/food', 'http...   \n",
       "15403  ['https://singaporeainews.org/blogs/news/singa...   \n",
       "\n",
       "                                           filename  \\\n",
       "8495   Food Security in Singapore_out_of_topic.json   \n",
       "8496   Food Security in Singapore_out_of_topic.json   \n",
       "8497   Food Security in Singapore_out_of_topic.json   \n",
       "8498   Food Security in Singapore_out_of_topic.json   \n",
       "15403  Food Security in Singapore_out_of_topic.json   \n",
       "\n",
       "                            topic       profile  \n",
       "8495   Food Security in Singapore  out_of_topic  \n",
       "8496   Food Security in Singapore  out_of_topic  \n",
       "8497   Food Security in Singapore  out_of_topic  \n",
       "8498   Food Security in Singapore  out_of_topic  \n",
       "15403  Food Security in Singapore  out_of_topic  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>factcheck_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3003</td>\n",
       "      <td>4</td>\n",
       "      <td>Trees help maintain water quality.</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4806</td>\n",
       "      <td>3</td>\n",
       "      <td>Opting for energy-efficient devices can contri...</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2590</td>\n",
       "      <td>2</td>\n",
       "      <td>The sun's size is constant.</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1322</td>\n",
       "      <td>2</td>\n",
       "      <td>Insects can significantly enhance gardening ef...</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3004</td>\n",
       "      <td>6</td>\n",
       "      <td>Disrupting the balance of the ecosystem can le...</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4775</td>\n",
       "      <td>3</td>\n",
       "      <td>Memes can also perpetuate misinformation.</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1554</td>\n",
       "      <td>4</td>\n",
       "      <td>Technology, like boats and drones, can aid in ...</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3058</td>\n",
       "      <td>3</td>\n",
       "      <td>Habitat destruction, such as deforestation, ca...</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3009</td>\n",
       "      <td>7</td>\n",
       "      <td>Trees prevent flooding.</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5142</td>\n",
       "      <td>2</td>\n",
       "      <td>We can explore the different types of volcanoe...</td>\n",
       "      <td>{'claims_check': [{'check_type': 'factuality',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_id  claim_id                                              claim  \\\n",
       "0          3003         4                 Trees help maintain water quality.   \n",
       "1          4806         3  Opting for energy-efficient devices can contri...   \n",
       "2          2590         2                        The sun's size is constant.   \n",
       "3          1322         2  Insects can significantly enhance gardening ef...   \n",
       "4          3004         6  Disrupting the balance of the ecosystem can le...   \n",
       "..          ...       ...                                                ...   \n",
       "95         4775         3          Memes can also perpetuate misinformation.   \n",
       "96         1554         4  Technology, like boats and drones, can aid in ...   \n",
       "97         3058         3  Habitat destruction, such as deforestation, ca...   \n",
       "98         3009         7                            Trees prevent flooding.   \n",
       "99         5142         2  We can explore the different types of volcanoe...   \n",
       "\n",
       "                                     factcheck_result  \n",
       "0   {'claims_check': [{'check_type': 'factuality',...  \n",
       "1   {'claims_check': [{'check_type': 'factuality',...  \n",
       "2   {'claims_check': [{'check_type': 'factuality',...  \n",
       "3   {'claims_check': [{'check_type': 'factuality',...  \n",
       "4   {'claims_check': [{'check_type': 'factuality',...  \n",
       "..                                                ...  \n",
       "95  {'claims_check': [{'check_type': 'factuality',...  \n",
       "96  {'claims_check': [{'check_type': 'factuality',...  \n",
       "97  {'claims_check': [{'check_type': 'factuality',...  \n",
       "98  {'claims_check': [{'check_type': 'factuality',...  \n",
       "99  {'claims_check': [{'check_type': 'factuality',...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_factuality_failure_checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>claim_idx</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>check_type</th>\n",
       "      <th>checkworthy</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>score</th>\n",
       "      <th>links</th>\n",
       "      <th>filename</th>\n",
       "      <th>topic</th>\n",
       "      <th>profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Food security in Singapore is defined as hav...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Food_security'...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Singapore relies heavily on food imports, maki...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Singapore imports over 90% of its food due t...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://amycookseats.com/how-much-food-does-...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ensuring food security helps maintain public h...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Food security ensures that individuals have ...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://www.maidencap.com/insights/the-impor...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The government actively works on strategies to...</td>\n",
       "      <td>I want you to help me understand what food sec...</td>\n",
       "      <td>Food security in Singapore means ensuring that...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>[\"The Singapore government has implemented the...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://www.mse.gov.sg/policies/food', 'http...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15403</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Singapore ensures a stable food supply through...</td>\n",
       "      <td>Oh, cool! So since Singapore relies on imports...</td>\n",
       "      <td>Singapore ensures a stable food supply through...</td>\n",
       "      <td>factuality</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['Singapore employs several key strategies to ...</td>\n",
       "      <td>PASS</td>\n",
       "      <td>['https://singaporeainews.org/blogs/news/singa...</td>\n",
       "      <td>Food Security in Singapore_out_of_topic.json</td>\n",
       "      <td>Food Security in Singapore</td>\n",
       "      <td>out_of_topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  claim_idx                                         claim_text  \\\n",
       "8495    0          0  Food security in Singapore means ensuring that...   \n",
       "8496    0          1  Singapore relies heavily on food imports, maki...   \n",
       "8497    0          2  Ensuring food security helps maintain public h...   \n",
       "8498    0          3  The government actively works on strategies to...   \n",
       "15403   1          0  Singapore ensures a stable food supply through...   \n",
       "\n",
       "                                                question  \\\n",
       "8495   I want you to help me understand what food sec...   \n",
       "8496   I want you to help me understand what food sec...   \n",
       "8497   I want you to help me understand what food sec...   \n",
       "8498   I want you to help me understand what food sec...   \n",
       "15403  Oh, cool! So since Singapore relies on imports...   \n",
       "\n",
       "                                                  answer  check_type  \\\n",
       "8495   Food security in Singapore means ensuring that...  factuality   \n",
       "8496   Food security in Singapore means ensuring that...  factuality   \n",
       "8497   Food security in Singapore means ensuring that...  factuality   \n",
       "8498   Food security in Singapore means ensuring that...  factuality   \n",
       "15403  Singapore ensures a stable food supply through...  factuality   \n",
       "\n",
       "      checkworthy                                          reasoning score  \\\n",
       "8495         PASS  ['Food security in Singapore is defined as hav...  PASS   \n",
       "8496         PASS  ['Singapore imports over 90% of its food due t...  PASS   \n",
       "8497         PASS  ['Food security ensures that individuals have ...  PASS   \n",
       "8498         PASS  [\"The Singapore government has implemented the...  PASS   \n",
       "15403        PASS  ['Singapore employs several key strategies to ...  PASS   \n",
       "\n",
       "                                                   links  \\\n",
       "8495   ['https://en.wikipedia.org/wiki/Food_security'...   \n",
       "8496   ['https://amycookseats.com/how-much-food-does-...   \n",
       "8497   ['https://www.maidencap.com/insights/the-impor...   \n",
       "8498   ['https://www.mse.gov.sg/policies/food', 'http...   \n",
       "15403  ['https://singaporeainews.org/blogs/news/singa...   \n",
       "\n",
       "                                           filename  \\\n",
       "8495   Food Security in Singapore_out_of_topic.json   \n",
       "8496   Food Security in Singapore_out_of_topic.json   \n",
       "8497   Food Security in Singapore_out_of_topic.json   \n",
       "8498   Food Security in Singapore_out_of_topic.json   \n",
       "15403  Food Security in Singapore_out_of_topic.json   \n",
       "\n",
       "                            topic       profile  \n",
       "8495   Food Security in Singapore  out_of_topic  \n",
       "8496   Food Security in Singapore  out_of_topic  \n",
       "8497   Food Security in Singapore  out_of_topic  \n",
       "8498   Food Security in Singapore  out_of_topic  \n",
       "15403  Food Security in Singapore  out_of_topic  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_factuality_failure_checks.iterrows():\n",
    "    # print(row[\"factcheck_result\"][\"claims_check\"][0][\"reasoning\"])\n",
    "    # print(row[\"factcheck_result\"][\"claims_check\"][0][\"score\"])\n",
    "    # print(row[\"factcheck_result\"][\"claims_check\"][0][\"check_type\"])\n",
    "    # print(row[\"factcheck_result\"][\"claims_check\"][0][\"links\"])\n",
    "\n",
    "    print(df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"]), \"reasoning\"])\n",
    "    print(row[\"factcheck_result\"][\"claims_check\"][0][\"reasoning\"])\n",
    "    \n",
    "    df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"]), \"reasoning\"] = json.dumps(row[\"factcheck_result\"][\"claims_check\"][0][\"reasoning\"])\n",
    "    df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"]), \"score\"] = json.dumps(row[\"factcheck_result\"][\"claims_check\"][0][\"score\"])\n",
    "    df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"]), \"links\"] = json.dumps(row[\"factcheck_result\"][\"claims_check\"][0][\"links\"])\n",
    "    print(df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_factuality_failure_checks.iterrows():    \n",
    "    df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"]), \"reasoning\"] = json.dumps(row[\"factcheck_result\"][\"claims_check\"][0][\"reasoning\"])\n",
    "    df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"]), \"score\"] = row[\"factcheck_result\"][\"claims_check\"][0][\"score\"]\n",
    "    df.loc[(df[\"id\"] == row[\"question_id\"]) & (df[\"claim_idx\"] == row[\"claim_id\"]), \"links\"] = json.dumps(row[\"factcheck_result\"][\"claims_check\"][0][\"links\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(consolidated_folder / \"hallucination_factchecking_results_with_filename_fixed_json_parsing_errors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis using the consolidated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby([\"check_type\", \"profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "PASS              13454\n",
       "FAIL                898\n",
       "UNVERIFIED            2\n",
       "PARTIALLY_PASS        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factuality bad_english\n",
      "1518 19\n",
      "0.9876382563435263\n",
      "factuality good\n",
      "1852 41\n",
      "0.9783412572636028\n",
      "factuality out_of_topic\n",
      "2754 12\n",
      "0.9956616052060737\n",
      "factuality unfactual\n",
      "2175 27\n",
      "0.9877384196185286\n",
      "hallucination bad_english\n",
      "1397 266\n",
      "0.8400481058328322\n",
      "hallucination good\n",
      "1666 275\n",
      "0.8583204533745492\n",
      "hallucination out_of_topic\n",
      "384 57\n",
      "0.8707482993197279\n",
      "hallucination unfactual\n",
      "1708 201\n",
      "0.8947092718700891\n"
     ]
    }
   ],
   "source": [
    "for index, group in grouped:\n",
    "    print(index[0], index[1])\n",
    "    print(len(group[group[\"score\"]==\"PASS\"]), len(group[group[\"score\"]==\"FAIL\"]))\n",
    "    print(len(group[group[\"score\"]==\"PASS\"])/(len(group[group[\"score\"]==\"PASS\"])+len(group[group[\"score\"]==\"FAIL\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hallucination_failure_checks[\"filename\"] = df_hallucination_failure_checks[\"question_id\"].map(id_to_filename)\n",
    "df_hallucination_failure_checks[\"topic\"] = df_hallucination_failure_checks[\"filename\"].apply(lambda x: x.split(\"_\", maxsplit=1)[0])\n",
    "df_hallucination_failure_checks[\"profile\"] = df_hallucination_failure_checks[\"filename\"].apply(lambda x: x.split(\"_\", maxsplit=1)[1][:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PASS'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hallucination_failure_checks[\"factcheck_result\"].iloc[0]['claims_check'][0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hallucination_failure_checks[\"score\"] = df_hallucination_failure_checks.apply(lambda row: row[\"factcheck_result\"][\"claims_check\"][0][\"score\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profile       score\n",
       "bad_english   PASS     250\n",
       "              FAIL      15\n",
       "good          PASS     256\n",
       "              FAIL      19\n",
       "out_of_topic  PASS      54\n",
       "              FAIL       3\n",
       "unfactual     PASS     174\n",
       "              FAIL      27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hallucination_failure_checks.groupby(\"profile\")[\"score\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29085"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'claim_idx', 'claim_text', 'question', 'answer', 'check_type',\n",
       "       'checkworthy', 'reasoning', 'score', 'links', 'filename', 'topic',\n",
       "       'profile'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'answerable_by_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'answerable_by_context'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswerable_by_context\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPASS\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'answerable_by_context'"
     ]
    }
   ],
   "source": [
    "len(df[df[\"answerable_by_context\"] == \"PASS\"][\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
